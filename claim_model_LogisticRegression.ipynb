{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifyer\n",
    "___\n",
    "\n",
    "This model is based on:\n",
    "\n",
    "```Bibtex\n",
    "@inproceedings{levyContextDependentClaim2014a,\n",
    "  title = {Context Dependent Claim Detection},\n",
    "  author = {Levy, Ran and Bilu, Yonatan and Hershcovich, Daniel and Aharoni, Ehud and Slonim, Noam},\n",
    "  date = {2014},\n",
    "  url = {https://aclanthology.org/C14-1141/},\n",
    "}\n",
    "```\n",
    "\n",
    "Features:\n",
    "- sentence-topic similarity\n",
    "- Linguistic expansion\n",
    "- Keyword that\n",
    "- sentiment\n",
    "- subjectivity\n",
    "\n",
    "Parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.features import ThatToken, Sentiment, Subjectivity, SentenceTopicSimilarity\n",
    "from src.dataset import load_dataset\n",
    "from config import PROJECT_NAME, DATASETS\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"LogisticRegression\"\n",
    "TRACKING = True\n",
    "FALSE_CLASS_BALANCE = 1.0\n",
    "\n",
    "dataset = DATASETS[\"dataset_2014\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset(dataset_path=os.path.join(dataset[\"base_path\"], dataset[\"data\"]), false_class_balance=FALSE_CLASS_BALANCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Encode features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = FeatureUnion(transformer_list=[(\"tf-idf\", TfidfVectorizer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = ColumnTransformer(\n",
    "    [\n",
    "        (\"tf-idf\", text_features, \"Sentence\"),\n",
    "        (\"that\", ThatToken(), \"Sentence\"),\n",
    "        (\"sentiment\", Sentiment(), \"Sentence\"),\n",
    "        (\"subjectivity\", Subjectivity(), \"Sentence\"),\n",
    "        (\"similarity\", SentenceTopicSimilarity(), [\"Sentence\", \"Article\"]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", column_trans),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"classify\", LogisticRegression(max_iter=200)),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jueri/Claim%20detection%20models/runs/2ofab9wy\" target=\"_blank\">restful-sponge-58</a></strong> to <a href=\"https://wandb.ai/jueri/Claim%20detection%20models\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRACKING:\n",
    "    wandb.init(project=PROJECT_NAME,\n",
    "            config={\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"setup\": str(pipe.get_feature_names_out),\n",
    "                \"dataset\": dataset[\"name\"],\n",
    "                \"train_data_size\": len(X_train),\n",
    "                \"validation_data_size\": 0,\n",
    "                \"test_data_size\": len(X_test),\n",
    "                \"batch_size\": None,\n",
    "                \"learning_rate\": None,\n",
    "                \"epochs\": None,\n",
    "                \"false_class_balance\": FALSE_CLASS_BALANCE\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] ........ (1 of 5) Processing tf-idf, total=   0.1s\n",
      "[ColumnTransformer] .......... (2 of 5) Processing that, total=   0.0s\n",
      "[ColumnTransformer] ..... (3 of 5) Processing sentiment, total=   0.3s\n",
      "[ColumnTransformer] .. (4 of 5) Processing subjectivity, total=   0.2s\n",
      "[ColumnTransformer] .... (5 of 5) Processing similarity, total=   1.8s\n",
      "[Pipeline] ..... (step 1 of 3) Processing preprocessing, total=   2.4s\n",
      "[Pipeline] ............ (step 2 of 3) Processing scaler, total=   0.0s\n",
      "[Pipeline] .......... (step 3 of 3) Processing classify, total=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('tf-idf',\n",
       "                                                  FeatureUnion(transformer_list=[('tf-idf',\n",
       "                                                                                  TfidfVectorizer())]),\n",
       "                                                  'Sentence'),\n",
       "                                                 ('that', ThatToken(),\n",
       "                                                  'Sentence'),\n",
       "                                                 ('sentiment', Sentiment(),\n",
       "                                                  'Sentence'),\n",
       "                                                 ('subjectivity',\n",
       "                                                  Subjectivity(), 'Sentence'),\n",
       "                                                 ('similarity',\n",
       "                                                  SentenceTopicSimilarity(),\n",
       "                                                  ['Sentence', 'Article'])],\n",
       "                                   verbose=True)),\n",
       "                ('scaler', StandardScaler(with_mean=False)),\n",
       "                ('classify', LogisticRegression(max_iter=200))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.75      0.76       147\n",
      "        True       0.75      0.77      0.76       147\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.76      0.76       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, Y_pred)\n",
    "recall = recall_score(y_test, Y_pred)\n",
    "precision = precision_score(y_test, Y_pred)\n",
    "accuracy = accuracy_score(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29804... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.7585</td></tr><tr><td>test_f1</td><td>0.76094</td></tr><tr><td>test_precision</td><td>0.75333</td></tr><tr><td>test_recall</td><td>0.76871</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">restful-sponge-58</strong>: <a href=\"https://wandb.ai/jueri/Claim%20detection%20models/runs/2ofab9wy\" target=\"_blank\">https://wandb.ai/jueri/Claim%20detection%20models/runs/2ofab9wy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211222_142117-2ofab9wy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRACKING:\n",
    "    wandb.log({'test_f1': f1})\n",
    "    wandb.log({'test_recall': recall})\n",
    "    wandb.log({'test_precision': precision})\n",
    "    wandb.log({'test_accuracy': accuracy})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

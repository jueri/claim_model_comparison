{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifyer\n",
    "___\n",
    "\n",
    "This model is based on:\n",
    "\n",
    "```Bibtex\n",
    "@inproceedings{levyContextDependentClaim2014a,\n",
    "  title = {Context Dependent Claim Detection},\n",
    "  author = {Levy, Ran and Bilu, Yonatan and Hershcovich, Daniel and Aharoni, Ehud and Slonim, Noam},\n",
    "  date = {2014},\n",
    "  url = {https://aclanthology.org/C14-1141/},\n",
    "}\n",
    "```\n",
    "\n",
    "Features:\n",
    "- sentence-topic similarity\n",
    "- Linguistic expansion\n",
    "- Keyword that\n",
    "- sentiment\n",
    "- subjectivity\n",
    "\n",
    "Parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.features import ThatToken, Sentiment, Subjectivity, SentenceTopicSimilarity\n",
    "from src.dataset import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, data[\"Claim\"], test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Encode features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = FeatureUnion(transformer_list=[(\"tf-idf\", TfidfVectorizer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = ColumnTransformer(\n",
    "    [\n",
    "        (\"tf-idf\", text_features, \"Sentence\"),\n",
    "        (\"that\", ThatToken(), \"Sentence\"),\n",
    "        (\"sentiment\", Sentiment(), \"Sentence\"),\n",
    "        (\"subjectivity\", Subjectivity(), \"Sentence\"),\n",
    "        (\"similarity\", SentenceTopicSimilarity(), [\"Sentence\", \"Article\"]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", column_trans),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"classify\", LogisticRegression(max_iter=200)),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] ........ (1 of 5) Processing tf-idf, total=   0.0s\n",
      "[ColumnTransformer] .......... (2 of 5) Processing that, total=   0.0s\n",
      "[ColumnTransformer] ..... (3 of 5) Processing sentiment, total=   0.3s\n",
      "[ColumnTransformer] .. (4 of 5) Processing subjectivity, total=   0.2s\n",
      "[ColumnTransformer] .... (5 of 5) Processing similarity, total=   1.1s\n",
      "[Pipeline] ..... (step 1 of 3) Processing preprocessing, total=   1.7s\n",
      "[Pipeline] ............ (step 2 of 3) Processing scaler, total=   0.0s\n",
      "[Pipeline] .......... (step 3 of 3) Processing classify, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('tf-idf',\n",
       "                                                  FeatureUnion(transformer_list=[('tf-idf',\n",
       "                                                                                  TfidfVectorizer())]),\n",
       "                                                  'Sentence'),\n",
       "                                                 ('that', ThatToken(),\n",
       "                                                  'Sentence'),\n",
       "                                                 ('sentiment', Sentiment(),\n",
       "                                                  'Sentence'),\n",
       "                                                 ('subjectivity',\n",
       "                                                  Subjectivity(), 'Sentence'),\n",
       "                                                 ('similarity',\n",
       "                                                  SentenceTopicSimilarity(),\n",
       "                                                  ['Sentence', 'Article'])],\n",
       "                                   verbose=True)),\n",
       "                ('scaler', StandardScaler(with_mean=False)),\n",
       "                ('classify', LogisticRegression(max_iter=200))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.71      0.72       235\n",
      "        True       0.74      0.78      0.76       259\n",
      "\n",
      "    accuracy                           0.74       494\n",
      "   macro avg       0.74      0.74      0.74       494\n",
      "weighted avg       0.74      0.74      0.74       494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

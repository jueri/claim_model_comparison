{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim Sentence Query\n",
    "___\n",
    "\n",
    "This model is based on:\n",
    "\n",
    "```Bibtex\n",
    "@inproceedings{levyUnsupervisedCorpuswideClaim2017,\n",
    "  title = {Unsupervised Corpus-Wide Claim Detection},\n",
    "  author = {Levy, Ran and Gretz, Shai and Sznajder, Benjamin and Hummel, Shay and Aharonov, Ranit and Slonim, Noam},\n",
    "  date = {2017},\n",
    "  doi = {10.18653/v1/w17-5110},\n",
    "}\n",
    "```\n",
    "\n",
    "Parameter:\n",
    "- Threshold for the retrieval score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from config import CLAIM_LEXICON_PATH, INDEX_PATH, PYSERINI_PATH\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "from src.searcher import convert_data, create_index\n",
    "from src.dataset import load_dataset\n",
    "from src.evaluation import confusion_matrix_plot\n",
    "\n",
    "from config import CLAIM_LEXICON_PATH, PROJECT_NAME, DATASETS\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"CSQ\"\n",
    "TRACKING = True\n",
    "FALSE_CLASS_BALANCE = 1.0\n",
    "\n",
    "dataset = DATASETS[\"dataset_2014\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset(dataset_path=os.path.join(dataset[\"base_path\"], dataset[\"data\"]), false_class_balance=FALSE_CLASS_BALANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CLAIM_LEXICON_PATH, \"r\") as inFile:  # load claim lexicon\n",
    "    claim_lexicon = inFile.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'data/pyserini'\n"
     ]
    }
   ],
   "source": [
    "convert_data(X_test[\"Sentence\"], data_path=PYSERINI_PATH)  # convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'data/pyserini/index'\n",
      "2021-12-22 14:23:46,025 INFO  [main] index.IndexCollection (IndexCollection.java:643) - Setting log level to INFO\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:646) - Starting indexer...\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:647) - ============ Loading Parameters ============\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:648) - DocumentCollection path: data/pyserini\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:649) - CollectionClass: JsonCollection\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:650) - Generator: DefaultLuceneDocumentGenerator\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:651) - Threads: 1\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:652) - Stemmer: porter\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:653) - Keep stopwords? false\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:654) - Stopwords:  null\n",
      "2021-12-22 14:23:46,033 INFO  [main] index.IndexCollection (IndexCollection.java:655) - Store positions? true\n",
      "2021-12-22 14:23:46,034 INFO  [main] index.IndexCollection (IndexCollection.java:656) - Store docvectors? true\n",
      "2021-12-22 14:23:46,034 INFO  [main] index.IndexCollection (IndexCollection.java:657) - Store document \"contents\" field? false\n",
      "2021-12-22 14:23:46,034 INFO  [main] index.IndexCollection (IndexCollection.java:658) - Store document \"raw\" field? true\n",
      "2021-12-22 14:23:46,034 INFO  [main] index.IndexCollection (IndexCollection.java:659) - Optimize (merge segments)? false\n",
      "2021-12-22 14:23:46,035 INFO  [main] index.IndexCollection (IndexCollection.java:660) - Whitelist: null\n",
      "2021-12-22 14:23:46,035 INFO  [main] index.IndexCollection (IndexCollection.java:661) - Pretokenized?: false\n",
      "2021-12-22 14:23:46,035 INFO  [main] index.IndexCollection (IndexCollection.java:681) - Directly building Lucene indexes...\n",
      "2021-12-22 14:23:46,036 INFO  [main] index.IndexCollection (IndexCollection.java:682) - Index path: data/pyserini/index\n",
      "2021-12-22 14:23:46,045 INFO  [main] index.IndexCollection (IndexCollection.java:731) - ============ Indexing Collection ============\n",
      "2021-12-22 14:23:46,078 INFO  [main] index.IndexCollection (IndexCollection.java:832) - Thread pool with 1 threads initialized.\n",
      "2021-12-22 14:23:46,078 INFO  [main] index.IndexCollection (IndexCollection.java:834) - Initializing collection in data/pyserini\n",
      "2021-12-22 14:23:46,082 INFO  [main] index.IndexCollection (IndexCollection.java:843) - 1 file found\n",
      "2021-12-22 14:23:46,082 INFO  [main] index.IndexCollection (IndexCollection.java:844) - Starting to index...\n",
      "2021-12-22 14:23:46,190 DEBUG [pool-4-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:248) - pyserini/data.json: 294 docs added.\n",
      "2021-12-22 14:23:46,490 INFO  [main] index.IndexCollection (IndexCollection.java:928) - Indexing Complete! 294 documents indexed\n",
      "2021-12-22 14:23:46,490 INFO  [main] index.IndexCollection (IndexCollection.java:929) - ============ Final Counter Values ============\n",
      "2021-12-22 14:23:46,490 INFO  [main] index.IndexCollection (IndexCollection.java:930) - indexed:              294\n",
      "2021-12-22 14:23:46,490 INFO  [main] index.IndexCollection (IndexCollection.java:931) - unindexable:            0\n",
      "2021-12-22 14:23:46,490 INFO  [main] index.IndexCollection (IndexCollection.java:932) - empty:                  0\n",
      "2021-12-22 14:23:46,490 INFO  [main] index.IndexCollection (IndexCollection.java:933) - skipped:                0\n",
      "2021-12-22 14:23:46,490 INFO  [main] index.IndexCollection (IndexCollection.java:934) - errors:                 0\n",
      "2021-12-22 14:23:46,491 INFO  [main] index.IndexCollection (IndexCollection.java:937) - Total 294 documents indexed in 00:00:00\n"
     ]
    }
   ],
   "source": [
    "searcher = create_index(data_path=PYSERINI_PATH, index_path=INDEX_PATH, language=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jueri/Claim%20detection%20models/runs/20cq2ytu\" target=\"_blank\">pious-oath-61</a></strong> to <a href=\"https://wandb.ai/jueri/Claim%20detection%20models\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRACKING:\n",
    "    wandb.init(project=PROJECT_NAME,\n",
    "            config={\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"setup\": \"pyserini index base config\",\n",
    "                \"dataset\": dataset[\"name\"],\n",
    "                \"train_data_size\": len(X_train),\n",
    "                \"validation_data_size\": 0,\n",
    "                \"test_data_size\": len(X_test),\n",
    "                \"batch_size\": None,\n",
    "                \"learning_rate\": None,\n",
    "                \"epochs\": None,\n",
    "                \"false_class_balance\": FALSE_CLASS_BALANCE\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = {idx: False for idx in X_test.index}  # create column for reults\n",
    "for main_concept in X_train[\"Article\"].unique():\n",
    "    # create query\n",
    "    should = [\"that\"] + main_concept.split(\" \") + claim_lexicon\n",
    "    # should = [\"that\"] + claim_lexicon\n",
    "\n",
    "    # search index\n",
    "    hits = searcher.search(\" \".join(should), k=1000)\n",
    "\n",
    "    # parse results\n",
    "    scores = []\n",
    "    for hit in hits:\n",
    "        if hit.score > 4:  # threshold for acaptable results\n",
    "            ids = json.loads(hit.raw)[\"id\"]\n",
    "            predicted[ids] = True\n",
    "        scores.append(hit.score)\n",
    "    y_pred = list(predicted.values())\n",
    "    \n",
    "    # pd.DataFrame(scores).plot(xlabel=\"position\", ylabel=\"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.58      0.56       147\n",
      "        True       0.55      0.51      0.53       147\n",
      "\n",
      "    accuracy                           0.54       294\n",
      "   macro avg       0.54      0.54      0.54       294\n",
      "weighted avg       0.54      0.54      0.54       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.to_list(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test.to_list(), y_pred)\n",
    "recall = recall_score(y_test.to_list(), y_pred)\n",
    "precision = precision_score(y_test.to_list(), y_pred)\n",
    "accuracy = accuracy_score(y_test.to_list(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30394... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.54422</td></tr><tr><td>test_f1</td><td>0.52817</td></tr><tr><td>test_precision</td><td>0.54745</td></tr><tr><td>test_recall</td><td>0.5102</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">pious-oath-61</strong>: <a href=\"https://wandb.ai/jueri/Claim%20detection%20models/runs/20cq2ytu\" target=\"_blank\">https://wandb.ai/jueri/Claim%20detection%20models/runs/20cq2ytu</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211222_142346-20cq2ytu/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRACKING:\n",
    "    wandb.log({'test_f1': f1})\n",
    "    wandb.log({'test_recall': recall})\n",
    "    wandb.log({'test_precision': precision})\n",
    "    wandb.log({'test_accuracy': accuracy})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(y_test, y_pred, label=[False, True], title=MODEL_NAME+\" confusion matrix\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
